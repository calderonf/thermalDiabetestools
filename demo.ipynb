{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo to test and show the functionality of the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('TKAgg') # Needed to have figures display properly. \n",
    "import flirimageextractor\n",
    "import Utils as u\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"C:\\\\Users\\\\Francisco\\\\Documents\\\\dataset_termal_destino\\\\Control_Image termal C_paciente 3 (VC)_flir_control_flir_20190907T092339.jpg\"\n",
    "#filename = \"D:\\\\FLIROne\\FLIR_20230426_044637_061.jpg\"\n",
    "#filename = \"D:\\\\FLIROne\\FLIR_20230426_044706_939.jpg\"\n",
    "flir = flirimageextractor.FlirImageExtractor(exiftool_path=\"C:\\\\Windows\\\\exiftool.exe\")\n",
    "flir.process_image(filename, RGB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(10,5))\\nplt.subplot(1,2,1)\\nplt.imshow(therm)\\nplt.title('Raw Thermal Image')\\nplt.subplot(1,2,2)\\nplt.imshow(rgb_fullres)\\nplt.title('RGB Full Resolution Image')\\nplt.show(block='TRUE') \\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "therm = flir.get_thermal_np()\n",
    "rgb_fullres = flir.get_rgb_np()\n",
    "\"\"\"\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(therm)\n",
    "plt.title('Raw Thermal Image')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(rgb_fullres)\n",
    "plt.title('RGB Full Resolution Image')\n",
    "plt.show(block='TRUE') \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image with offsetx=-1, offsety=37, pipx2=479, pipy2=639, real2ir=1.22885632514954\n"
     ]
    }
   ],
   "source": [
    "colormap_image, Imsalida,temp_img_resized,image_copy = u.extract_images(flir,plot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u.save_thermal_csv(temp_img_resized,\"temperature_examples.csv\",delimiter=\";\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# second part of the demo get the perspective transformation between two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image with offsetx=-1, offsety=37, pipx2=479, pipy2=639, real2ir=1.22885632514954\n"
     ]
    }
   ],
   "source": [
    "filename2 = \"C:\\\\Users\\\\Francisco\\\\Documents\\\\dataset_termal_destino\\\\Control_Image termal C_paciente 3 (VC)_flir_control_flir_20190907T092409.jpg\"\n",
    "flir2 = flirimageextractor.FlirImageExtractor(exiftool_path=\"C:\\\\Windows\\\\exiftool.exe\")\n",
    "flir2.process_image(filename2, RGB=True)\n",
    "therm2 = flir2.get_thermal_np()\n",
    "rgb_fullres2 = flir2.get_rgb_np()\n",
    "colormap_image2, Imsalida2,temp_img_resized2,image_copy2 = u.extract_images(flir2,plot=0)\n",
    "#u.save_thermal_csv(temp_img_resized2,\"temperature_examples2.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fethearing_bin_to_color(binary_image, color_image):\n",
    "    # Operación de cierre morfológico con un kernel elíptico de tamaño 5x5\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n",
    "    closed_image1 = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)\n",
    "    kerne2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    closed_image = cv2.morphologyEx(closed_image1, cv2.MORPH_CLOSE, kerne2)\n",
    "    \n",
    "    # Fethearing usando filtro guiado\n",
    "    filtered_image = cv2.ximgproc.guidedFilter(color_image, closed_image, 50, eps=1e-4)#5, eps=1e-4\n",
    "    \n",
    "    # Umbralización de la imagen filtrada\n",
    "    _, thresholded_image = cv2.threshold(filtered_image,20, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    kerne3 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    output_image = cv2.morphologyEx(thresholded_image, cv2.MORPH_OPEN, kerne3)\n",
    "    \n",
    "    return filtered_image,output_image\n",
    "\n",
    "def draw_largest_contours(image):\n",
    "    # Hacer una AND entre los 3 canales de la imagen\n",
    "    and_image = np.bitwise_and(image[:,:,0], np.bitwise_and(image[:,:,1], image[:,:,2]))\n",
    "\n",
    "    # Encontrar los contornos más externos\n",
    "    contours, _ = cv2.findContours(and_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Ordenar los contornos por su área de mayor a menor\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    # Encontrar los dos contornos más grandes\n",
    "    largest_contours = contours[:2]\n",
    "\n",
    "    # Crear una nueva imagen binaria con solo los contornos más grandes dibujados\n",
    "    new_image = np.zeros_like(image)\n",
    "    cv2.drawContours(new_image, largest_contours, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Convertir la imagen a binaria\n",
    "    new_image = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
    "    _, new_image = cv2.threshold(new_image, 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def resize_contour_boxes_rotated(binary_image, color_image, thermal_image, percentage):\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rects = [cv2.minAreaRect(cnt) for cnt in contours]\n",
    "    offset = percentage / 100 / 2\n",
    "    enlarged_boxes = []\n",
    "    for rect in rects:\n",
    "        center, size, angle = rect\n",
    "        width = size[0] * (1 + offset * 2)\n",
    "        height = size[1] * (1 + offset * 2)\n",
    "        enlarged_boxes.append(cv2.boxPoints(((center[0], center[1]), (width, height), angle)))\n",
    "\n",
    "    # Crea una lista de imágenes con el contenido de la imagen a color en la ubicación de los rectángulos contenedores\n",
    "    result_images = []\n",
    "    for box in enlarged_boxes:\n",
    "        rect = cv2.minAreaRect(box)\n",
    "        center, size, angle = rect\n",
    "        width = int(size[0])\n",
    "        height = int(size[1])\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "        rotated = cv2.warpAffine(color_image, M, (color_image.shape[1], color_image.shape[0]))\n",
    "        result_images.append(rotated[int(center[1] - height / 2):int(center[1] + height / 2), int(center[0] - width / 2):int(center[0] + width / 2)])\n",
    "\n",
    "    return result_images,result_images\n",
    "\n",
    "def resize_contour_boxes(binary_image, color_image, thermal_image, percentage=10):\n",
    "    # Encuentra los contornos externos de la imagen binaria\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Encuentra los mínimos rectángulos contenedores de la lista de contornos\n",
    "    boxes = [cv2.boundingRect(cnt) for cnt in contours]\n",
    "    # Calcula el desplazamiento para aplicar el porcentaje simétricamente\n",
    "    offset = percentage / 100 / 2\n",
    "    # Incrementa el tamaño de los rectángulos contenedores según el porcentaje especificado\n",
    "    enlarged_boxes = [(int(x - w * offset), int(y - h * offset), int(w * (1 + offset * 2)), int(h * (1 + offset * 2))) for (x, y, w, h) in boxes]\n",
    "    # Crea una lista de imágenes con el contenido de la imagen a color en la ubicación de los rectángulos contenedores\n",
    "    result_images = []\n",
    "    for box in enlarged_boxes:\n",
    "        x, y, w, h = box\n",
    "        result_images.append(color_image[y:y+h, x:x+w])\n",
    "    result_thermal=[]\n",
    "    for box in enlarged_boxes:\n",
    "        x, y, w, h = box\n",
    "        result_thermal.append(thermal_image[y:y+h, x:x+w])\n",
    "    return result_images,result_thermal\n",
    "        \n",
    "def plot_images_and_thermal(image_list,thermal_list):\n",
    "    num_images = len(image_list)+len(thermal_list)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(12, 4))\n",
    "    for i in range(len(image_list)):\n",
    "        axes[i].imshow(image_list[i])\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "    for i in range(len(thermal_list)):\n",
    "        axes[len(image_list)+i].imshow(thermal_list[i], cmap='jet')\n",
    "        axes[len(image_list)+i].axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def apply_mask(image, mask):\n",
    "    # Verifica si las dimensiones de las imágenes son iguales\n",
    "    if image.shape[:2] != mask.shape[:2]:\n",
    "        raise ValueError(\"Las dimensiones de las imágenes no coinciden.\")\n",
    "\n",
    "    # Crea una imagen negra del mismo tamaño que la imagen original\n",
    "    masked_image = np.zeros_like(image)\n",
    "\n",
    "    # Copia los píxeles de la imagen original donde la máscara es uno\n",
    "    masked_image[mask.astype(bool)] = image[mask.astype(bool)]\n",
    "\n",
    "    return masked_image\n",
    "\n",
    "def Find_feets(Color_Image,thermal_image,percentage=0):\n",
    "    output=u.segment_skin(Color_Image)\n",
    "    _,thresholded_image=fethearing_bin_to_color(output, Color_Image)\n",
    "    binary=draw_largest_contours(thresholded_image)\n",
    "    #segmented_Feet,segmented_temps=resize_contour_boxes(binary, apply_mask(Color_Image, binary), thermal_image, percentage=percentage)\n",
    "    #segmented_Feet,segmented_temps=resize_contour_boxes(binary, Color_Image, thermal_image, percentage=percentage)\n",
    "    segmented_Feet,segmented_temps=resize_contour_boxes_rotated(binary, Color_Image, thermal_image, percentage=percentage)\n",
    "    \n",
    "    return segmented_Feet,segmented_temps\n",
    "\n",
    "def matchbydescriptors(image_a,image_b):\n",
    "    # Detectar y extraer puntos clave y descriptores en ambas imágenes\n",
    "    orb = cv2.SIFT_create(5000)\n",
    "    keypoints_a, descriptors_a = orb.detectAndCompute(image_a, None)\n",
    "    keypoints_b, descriptors_b = orb.detectAndCompute(image_b, None)\n",
    "    # Encontrar los puntos correspondientes entre las imágenes\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    \n",
    "    \n",
    "    matches = matcher.match(descriptors_a, descriptors_b)\n",
    "    # Seleccionar los mejores N puntos correspondientes\n",
    "    n_points = int(0.5*len(matches))\n",
    "    matches = sorted(matches, key=lambda x: x.distance)[:n_points]\n",
    "    # Extraer las coordenadas de los puntos correspondientes en ambas imágenes\n",
    "    points_a = np.float32([keypoints_a[match.queryIdx].pt for match in matches]).reshape(-1, 1, 2)\n",
    "    points_b = np.float32([keypoints_b[match.trainIdx].pt for match in matches]).reshape(-1, 1, 2)\n",
    "    # Calcular la matriz de homografía\n",
    "    homography_matrix, _ = cv2.findHomography(points_b, points_a, cv2.RANSAC, 5.0)\n",
    "    # Realizar la transformación perspectiva de la imagen B a la perspectiva de la imagen A\n",
    "    image_b_transformed = cv2.warpPerspective(image_b, homography_matrix, (image_a.shape[1], image_a.shape[0]))\n",
    "    # Superponer las imágenes transformadas\n",
    "    alpha = 0.5\n",
    "    output_image = cv2.addWeighted(image_a, 1 - alpha, image_b_transformed, alpha, 0)\n",
    "    return output_image,homography_matrix\n",
    "\n",
    "def visualize_descriptors(image_a, image_b):\n",
    "    # Detectar y extraer puntos clave y descriptores en ambas imágenes\n",
    "    orb = cv2.SIFT_create(5000)\n",
    "    keypoints_a, descriptors_a = orb.detectAndCompute(image_a, None)\n",
    "    keypoints_b, descriptors_b = orb.detectAndCompute(image_b, None)\n",
    "\n",
    "    # Visualizar los puntos clave en la imagen A\n",
    "    img_a_with_keypoints = cv2.drawKeypoints(image_a, keypoints_a, None)\n",
    "\n",
    "    # Visualizar los puntos clave en la imagen B\n",
    "    img_b_with_keypoints = cv2.drawKeypoints(image_b, keypoints_b, None)\n",
    "\n",
    "    # Mostrar las imágenes con los puntos clave utilizando Matplotlib\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(cv2.cvtColor(img_a_with_keypoints, cv2.COLOR_BGR2RGB))\n",
    "    ax[0].set_title('Imagen A con puntos clave')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(cv2.cvtColor(img_b_with_keypoints, cv2.COLOR_BGR2RGB))\n",
    "    ax[1].set_title('Imagen B con puntos clave')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "import itk\n",
    "\n",
    "def register_images(image_a, image_b):\n",
    "    # Convertir las imágenes a formato ITK\n",
    "    itk_image_a = itk.GetImageFromArray(image_a)\n",
    "    itk_image_b = itk.GetImageFromArray(image_b)\n",
    "\n",
    "    # Definir los tipos de imágenes y transformaciones\n",
    "    PixelType = itk.UC\n",
    "    Dimension = 2\n",
    "    ImageType = itk.Image[PixelType, Dimension]\n",
    "    TransformType = itk.TranslationTransform[itk.D, Dimension]\n",
    "\n",
    "    # Crear un registrador de imágenes\n",
    "    registration_filter = itk.ImageRegistrationMethod.New(ImageType, ImageType)\n",
    "\n",
    "    # Configurar los parámetros del registrador\n",
    "    optimizer = itk.RegularStepGradientDescentOptimizerv4.New()\n",
    "    metric = itk.MeanSquaresImageToImageMetricv4.New(ImageType, ImageType)\n",
    "    interpolator = itk.LinearInterpolateImageFunction.New(ImageType, itk.D)\n",
    "\n",
    "    registration_filter.SetOptimizer(optimizer)\n",
    "    registration_filter.SetMetric(metric)\n",
    "    registration_filter.SetInterpolator(interpolator)\n",
    "\n",
    "    # Definir las transformaciones iniciales y estimar la transformación final\n",
    "    initial_transform = TransformType.New()\n",
    "    identity_transform = TransformType.New()\n",
    "    identity_transform.SetIdentity()\n",
    "\n",
    "    registration_filter.SetMovingInitialTransform(initial_transform)\n",
    "    registration_filter.SetFixedInitialTransform(identity_transform)\n",
    "    registration_filter.SetMovingImage(itk_image_b)\n",
    "    registration_filter.SetFixedImage(itk_image_a)\n",
    "\n",
    "    registration_filter.Update()\n",
    "\n",
    "    # Obtener la imagen registrada\n",
    "    registered_image = itk.GetArrayFromImage(registration_filter.GetOutput())\n",
    "\n",
    "    return registered_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_Feet,segmented_temps=Find_feets(image_copy,temp_img_resized,percentage=20)\n",
    "plot_images_and_thermal(segmented_Feet,segmented_temps)\n",
    "segmented_Feet2,segmented_temps2=Find_feets(image_copy2,temp_img_resized2,percentage=20)\n",
    "plot_images_and_thermal(segmented_Feet2,segmented_temps2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_descriptors(segmented_Feet[0],segmented_Feet2[0])\n",
    "visualize_descriptors(segmented_Feet[1],segmented_Feet2[1])\n",
    "\n",
    "\n",
    "\n",
    "output_image,homography_matrix=u.matchbydescriptors(segmented_Feet[0],segmented_Feet2[0])\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(output_image)\n",
    "plt.title('registration between images')\n",
    "plt.show(block='TRUE') \n",
    "\n",
    "output_image,homography_matrix=u.matchbydescriptors(segmented_Feet[1],segmented_Feet2[1])\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(output_image)\n",
    "plt.title('registration between images')\n",
    "plt.show(block='TRUE') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TemplateTypeError",
     "evalue": "itk.ImageRegistrationMethod is not wrapped for input type `None`.\n\nTo limit the size of the package, only a limited number of\ntypes are available in ITK Python. To print the supported\ntypes, run the following command in your python environment:\n\n    itk.ImageRegistrationMethod.GetTypes()\n\nPossible solutions:\n* If you are an application user:\n** Convert your input image into a supported format (see below).\n** Contact developer to report the issue.\n* If you are an application developer, force input images to be\nloaded in a supported pixel type.\n\n    e.g.: instance = itk.ImageRegistrationMethod[itk.Image[itk.SS,2], itk.Image[itk.SS,2]].New(my_input)\n\n* (Advanced) If you are an application developer, build ITK Python yourself and\nturned to `ON` the corresponding CMake option to wrap the pixel type or image\ndimension you need. When configuring ITK with CMake, you can set\n`ITK_WRAP_${type}` (replace ${type} with appropriate pixel type such as\n`double`). If you need to support images with 4 or 5 dimensions, you can add\nthese dimensions to the list of dimensions in the CMake variable\n`ITK_WRAP_IMAGE_DIMS`.\n\nSupported input types:\n\nitk.Image[itk.SS,2]\nitk.Image[itk.SS,3]\nitk.Image[itk.SS,4]\nitk.Image[itk.UC,2]\nitk.Image[itk.UC,3]\nitk.Image[itk.UC,4]\nitk.Image[itk.US,2]\nitk.Image[itk.US,3]\nitk.Image[itk.US,4]\nitk.Image[itk.F,2]\nitk.Image[itk.F,3]\nitk.Image[itk.F,4]\nitk.Image[itk.D,2]\nitk.Image[itk.D,3]\nitk.Image[itk.D,4]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTemplateTypeError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# using a different approach\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m registered_image \u001b[39m=\u001b[39mregister_images(segmented_Feet[\u001b[39m0\u001b[39;49m],segmented_Feet2[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m      5\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m5\u001b[39m))\n\u001b[0;32m      6\u001b[0m plt\u001b[39m.\u001b[39mimshow(registered_image)\n",
      "Cell \u001b[1;32mIn[8], line 188\u001b[0m, in \u001b[0;36mregister_images\u001b[1;34m(image_a, image_b)\u001b[0m\n\u001b[0;32m    185\u001b[0m TransformType \u001b[39m=\u001b[39m itk\u001b[39m.\u001b[39mTranslationTransform[itk\u001b[39m.\u001b[39mD, Dimension]\n\u001b[0;32m    187\u001b[0m \u001b[39m# Crear un registrador de imágenes\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m registration_filter \u001b[39m=\u001b[39m itk\u001b[39m.\u001b[39;49mImageRegistrationMethod\u001b[39m.\u001b[39;49mNew(ImageType, ImageType)\n\u001b[0;32m    190\u001b[0m \u001b[39m# Configurar los parámetros del registrador\u001b[39;00m\n\u001b[0;32m    191\u001b[0m optimizer \u001b[39m=\u001b[39m itk\u001b[39m.\u001b[39mRegularStepGradientDescentOptimizerv4\u001b[39m.\u001b[39mNew()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\itk\\support\\template_class.py:734\u001b[0m, in \u001b[0;36mitkTemplate.New\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m         \u001b[39mimport\u001b[39;00m \u001b[39mitk\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m         \u001b[39mraise\u001b[39;00m itk\u001b[39m.\u001b[39mTemplateTypeError(\u001b[39mself\u001b[39m, input_type)\n\u001b[0;32m    735\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[\u001b[39mlist\u001b[39m(keys)[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39mNew(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTemplateTypeError\u001b[0m: itk.ImageRegistrationMethod is not wrapped for input type `None`.\n\nTo limit the size of the package, only a limited number of\ntypes are available in ITK Python. To print the supported\ntypes, run the following command in your python environment:\n\n    itk.ImageRegistrationMethod.GetTypes()\n\nPossible solutions:\n* If you are an application user:\n** Convert your input image into a supported format (see below).\n** Contact developer to report the issue.\n* If you are an application developer, force input images to be\nloaded in a supported pixel type.\n\n    e.g.: instance = itk.ImageRegistrationMethod[itk.Image[itk.SS,2], itk.Image[itk.SS,2]].New(my_input)\n\n* (Advanced) If you are an application developer, build ITK Python yourself and\nturned to `ON` the corresponding CMake option to wrap the pixel type or image\ndimension you need. When configuring ITK with CMake, you can set\n`ITK_WRAP_${type}` (replace ${type} with appropriate pixel type such as\n`double`). If you need to support images with 4 or 5 dimensions, you can add\nthese dimensions to the list of dimensions in the CMake variable\n`ITK_WRAP_IMAGE_DIMS`.\n\nSupported input types:\n\nitk.Image[itk.SS,2]\nitk.Image[itk.SS,3]\nitk.Image[itk.SS,4]\nitk.Image[itk.UC,2]\nitk.Image[itk.UC,3]\nitk.Image[itk.UC,4]\nitk.Image[itk.US,2]\nitk.Image[itk.US,3]\nitk.Image[itk.US,4]\nitk.Image[itk.F,2]\nitk.Image[itk.F,3]\nitk.Image[itk.F,4]\nitk.Image[itk.D,2]\nitk.Image[itk.D,3]\nitk.Image[itk.D,4]\n"
     ]
    }
   ],
   "source": [
    "# using a different approach\n",
    "\n",
    "\n",
    "registered_image =register_images(segmented_Feet[0],segmented_Feet2[0])\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(registered_image)\n",
    "plt.title('registered_images')\n",
    "plt.show(block='TRUE') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thermal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
